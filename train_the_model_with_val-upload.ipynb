{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"./DATA/\"\n",
    "\n",
    "data_type = \"ap\"   # ap or lateral\n",
    "rnd_seed = str(time.time())[-3:]\n",
    "run_name_origin = data_type+\"_\"+\"--\"+rnd_seed\n",
    "\n",
    "\n",
    "size_w = 500\n",
    "size_h = 600\n",
    "tr_ratio = 0.6\n",
    "te_ratio = 0.2\n",
    "\n",
    "learning_rate = 3e-5\n",
    "epoch = 200\n",
    "\n",
    "print(run_name_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_image(input_path):\n",
    "    img = Image.open(input_path)\n",
    "    img = img.resize([size_w,size_h])\n",
    "    rslt = np.asarray(img)/255\n",
    "    \n",
    "    return rslt\n",
    "\n",
    "def load_many_image(input_path):\n",
    "    rslt = np.zeros([len(input_path),size_h,size_w,3])\n",
    "    for i,img_path in enumerate(input_path):\n",
    "        rslt[i] = load_one_image(img_path)\n",
    "        \n",
    "    return rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal =0, abn = 1\n",
    "all_path_0 = glob.glob(data_path+\"normal/\"+data_type+\"/*.jpg\")\n",
    "all_path_1_origin = glob.glob(data_path+\"abnormal/\"+data_type+\"/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(int(rnd_seed))\n",
    "random.shuffle(all_path_0)\n",
    "random.shuffle(all_path_1_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path_1_1 = all_path_1_origin[:208]\n",
    "all_path_1_2 = all_path_1_origin[208:208*2]\n",
    "all_path_1_3 = all_path_1_origin[208*2:208*3]\n",
    "all_path_1_4 = all_path_1_origin[208*3:208*4]\n",
    "all_path_1_5 = all_path_1_origin[208*4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_path_1 = all_path_1_1\n",
    "\n",
    "run_name = run_name_origin+\"_1\"\n",
    "\n",
    "\n",
    "# normal =0, abn = 1\n",
    "path_tr_0 = all_path_0[:111]\n",
    "path_tr_1 = all_path_1[:111]\n",
    "\n",
    "path_vl_0 = all_path_0[int(len(all_path_0)*tr_ratio):int(len(all_path_0)*(1-te_ratio))]\n",
    "path_vl_1 = all_path_1[int(len(all_path_0)*tr_ratio):int(len(all_path_1)*(1-te_ratio))]\n",
    "path_vl_1 = path_vl_1[:len(path_vl_0)]\n",
    "\n",
    "path_te_0 = all_path_0[-38:]\n",
    "path_te_1 = all_path_1[-60:]\n",
    "\n",
    "path_tr = np.concatenate([path_tr_0,path_tr_1])\n",
    "path_vl = np.concatenate([path_vl_0,path_vl_1])\n",
    "path_te = np.concatenate([path_te_0,path_te_1])\n",
    "\n",
    "target_label_tr = ['normal']*len(path_tr_0) +['abnormal']*len(path_tr_1)\n",
    "target_label_vl = ['normal']*len(path_vl_0) +['abnormal']*len(path_vl_1)\n",
    "target_label_te = ['normal']*len(path_te_0) +['abnormal']*len(path_te_1)\n",
    "\n",
    "target_tr = np.asarray(pd.get_dummies(target_label_tr))\n",
    "target_vl = np.asarray(pd.get_dummies(target_label_vl))\n",
    "target_te = np.asarray(pd.get_dummies(target_label_te))\n",
    "# abnormal = [1,0]   normal = [0,1]\n",
    "\n",
    "\n",
    "print( np.unique(target_label_tr,return_counts=True) )\n",
    "print( np.unique(target_label_vl,return_counts=True) )\n",
    "print( np.unique(target_label_te,return_counts=True) )\n",
    "print(target_tr[:5])\n",
    "print(target_label_tr[:5])\n",
    "\n",
    "\n",
    "input_tr = load_many_image(path_tr)\n",
    "input_vl = load_many_image(path_vl)\n",
    "input_te = load_many_image(path_te)\n",
    "\n",
    "datagen_tr = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range = [0.9,1.1],\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval = 0)\n",
    "datagen_te = ImageDataGenerator()\n",
    "\n",
    "gen_tr = datagen_tr.flow(x = input_tr,y=target_tr,batch_size=8)\n",
    "gen_vl = datagen_te.flow(x = input_vl,y=target_vl,batch_size=8)\n",
    "gen_te = datagen_te.flow(x = input_te,y=target_te,batch_size=8)\n",
    "\n",
    "step_per_epoch = int( len(input_tr)/8 )\n",
    "\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "predictions = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "callback_tb = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/\"+run_name+\"/\".format(run_name), profile_batch = 100000000)\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath = run_name+\"_best.hdf5\",monitor='val_accuracy',\n",
    "                                                verbose=1, save_best_only=True,mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x = gen_tr, epochs=epoch, \n",
    "          validation_data=gen_vl, \n",
    "          steps_per_epoch = step_per_epoch,\n",
    "                    max_queue_size=15,\n",
    "                    workers=8,\n",
    "          callbacks=[callback_tb,callback_mc])\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(run_name+\"_best.hdf5\")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "\n",
    "def CAM_multiclass(model,img_set,which_label=None):\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    final_conv = model.layers[-3]\n",
    "    get_output = K.function([model.layers[0].input],[final_conv.output,model.layers[-1].output])\n",
    "\n",
    "    cam_output = np.zeros(shape = [img_set.shape[0],img_set.shape[1],img_set.shape[2],3])\n",
    "\n",
    "    for img_index in range(img_set.shape[0]):\n",
    "        input_img = img_set[img_index:img_index+1,...]\n",
    "        #input_img_rgb = np.concatenate([input_img, input_img, input_img], axis = 3)\n",
    "        [conv_output,predictions] = get_output([input_img])\n",
    "        conv_output = conv_output[0,...]\n",
    "        pred_label = np.argmax(predictions)\n",
    "\n",
    "        cam = np.zeros(shape = conv_output.shape[:-1])\n",
    "        if which_label==None:\n",
    "            for i, w in enumerate(class_weights[:, pred_label]): \n",
    "                cam += w * conv_output[...,i]\n",
    "        if not (which_label==None):\n",
    "            for i, w in enumerate(class_weights[:,  which_label[img_index] ]):  \n",
    "                cam += w * conv_output[...,i]\n",
    "        cam /= np.max(cam)\n",
    "\n",
    "        cam_resize = cv2.resize(cam[:,:], (img_set.shape[2],img_set.shape[1]))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*cam_resize), cv2.COLORMAP_JET)\n",
    "        heatmap = heatmap[...,(2,1,0)]\n",
    "        heatmap[np.where(cam_resize < 0.1)] = 0\n",
    "        cam_output[img_index,:,:,:] = heatmap*0.3 + input_img[0,:,:,:]*255\n",
    "        #cam_output[img_index,:,:,:] = heatmap*0.5 + input_img_rgb[0,:,:,:]\n",
    "            \n",
    "    return cam_output\n",
    "\n",
    "pred_te = model.predict(input_te, batch_size=4)\n",
    "pred_label_te = np.argmax(pred_te,axis=1).astype(\"str\")\n",
    "pred_label_te = np.where(pred_label_te==\"1\", \"normal\", pred_label_te)\n",
    "pred_label_te = np.where(pred_label_te==\"0\", \"abnormal\", pred_label_te)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "auc_te = roc_auc_score(target_te[:,0],pred_te[:,0])\n",
    "\n",
    "acc_te = accuracy_score(target_label_te, pred_label_te)\n",
    "cf_mtx = confusion_matrix(target_label_te,pred_label_te)\n",
    "pr_re_f1_report = classification_report(y_true = target_label_te, y_pred = pred_label_te)\n",
    "\n",
    "\n",
    "result_report = pd.DataFrame(data = {\"ID\":[s.split(\"/\")[-1] for s in path_te]\n",
    "                                     ,\"GT_Label\" : target_label_te \n",
    "                                     ,\"pred_Label\" : pred_label_te\n",
    "                                 ,\"GT\" : [str(s) for s in target_te ]\n",
    "                                 ,\"pred\" : [str(s) for s in np.round(pred_te,3) ]\n",
    "                                 ,\"Correct?\" : np.array(target_label_te)==np.array(pred_label_te) })\n",
    "result_report = result_report[['ID',\"GT_Label\",\"pred_Label\",'GT','pred','Correct?']]\n",
    "\n",
    "\n",
    "result_report.to_csv(\"pred_rslt_TE\"+run_name+\".csv\",index=False)\n",
    "\n",
    "pd.set_option('display.width', 999999)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 99999)\n",
    "\n",
    "with open(\"Report-\"+run_name+\".txt\",'w') as text_file:\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Overall accuracy on test set : \",acc_te,file=text_file)\n",
    "    print(\"AUC on test set : \",auc_te,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Confusion Matrix (row=actual, col=predicted)\",file=text_file)\n",
    "    print(\"abnormal / normal\",file=text_file)\n",
    "#     print(class_name_list,file=text_file)\n",
    "    print(cf_mtx,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Classification Report :\",file=text_file)\n",
    "    print(pr_re_f1_report,file=text_file)\n",
    "    print(\"------------------RESULT REPORT--------------------\",file=text_file)\n",
    "    print(result_report,file=text_file)\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')\n",
    "\n",
    "cam_rslt_te = CAM_multiclass(model,input_te)\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(\"./CAM/\"+run_name,exist_ok=True)\n",
    "for i in range(len(pred_label_te)):\n",
    "    cv2.imwrite(\"./CAM/\"+run_name+\"/target\"+str(target_label_te[i])+\"pred\"+str(pred_label_te[i])+\"-ID_\"+str(path_te[i].split(\"\\\\\")[-1])\n",
    "               ,cam_rslt_te[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_path_1 = all_path_1_2\n",
    "run_name = run_name_origin+\"_2\"\n",
    "\n",
    "\n",
    "\n",
    "# normal =0, abn = 1\n",
    "path_tr_0 = all_path_0[:111]\n",
    "path_tr_1 = all_path_1[:111]\n",
    "\n",
    "path_vl_0 = all_path_0[int(len(all_path_0)*tr_ratio):int(len(all_path_0)*(1-te_ratio))]\n",
    "path_vl_1 = all_path_1[int(len(all_path_0)*tr_ratio):int(len(all_path_1)*(1-te_ratio))]\n",
    "path_vl_1 = path_vl_1[:len(path_vl_0)]\n",
    "\n",
    "path_te_0 = all_path_0[-38:]\n",
    "path_te_1 = all_path_1[-60:]\n",
    "\n",
    "path_tr = np.concatenate([path_tr_0,path_tr_1])\n",
    "path_vl = np.concatenate([path_vl_0,path_vl_1])\n",
    "path_te = np.concatenate([path_te_0,path_te_1])\n",
    "\n",
    "target_label_tr = ['normal']*len(path_tr_0) +['abnormal']*len(path_tr_1)\n",
    "target_label_vl = ['normal']*len(path_vl_0) +['abnormal']*len(path_vl_1)\n",
    "target_label_te = ['normal']*len(path_te_0) +['abnormal']*len(path_te_1)\n",
    "\n",
    "target_tr = np.asarray(pd.get_dummies(target_label_tr))\n",
    "target_vl = np.asarray(pd.get_dummies(target_label_vl))\n",
    "target_te = np.asarray(pd.get_dummies(target_label_te))\n",
    "# abnormal = [1,0]   normal = [0,1]\n",
    "\n",
    "\n",
    "print( np.unique(target_label_tr,return_counts=True) )\n",
    "print( np.unique(target_label_vl,return_counts=True) )\n",
    "print( np.unique(target_label_te,return_counts=True) )\n",
    "print(target_tr[:5])\n",
    "print(target_label_tr[:5])\n",
    "\n",
    "\n",
    "input_tr = load_many_image(path_tr)\n",
    "input_vl = load_many_image(path_vl)\n",
    "input_te = load_many_image(path_te)\n",
    "\n",
    "datagen_tr = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range = [0.9,1.1],\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval = 0)\n",
    "datagen_te = ImageDataGenerator()\n",
    "\n",
    "gen_tr = datagen_tr.flow(x = input_tr,y=target_tr,batch_size=8)\n",
    "gen_vl = datagen_te.flow(x = input_vl,y=target_vl,batch_size=8)\n",
    "gen_te = datagen_te.flow(x = input_te,y=target_te,batch_size=8)\n",
    "\n",
    "step_per_epoch = int( len(input_tr)/8 )\n",
    "\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "predictions = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "callback_tb = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/\"+run_name+\"/\".format(run_name), profile_batch = 100000000)\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath = run_name+\"_best.hdf5\",monitor='val_accuracy',\n",
    "                                                verbose=1, save_best_only=True,mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x = gen_tr, epochs=epoch, \n",
    "          validation_data=gen_vl, \n",
    "          steps_per_epoch = step_per_epoch,\n",
    "                    max_queue_size=15,\n",
    "                    workers=8,\n",
    "          callbacks=[callback_tb,callback_mc])\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(run_name+\"_best.hdf5\")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "\n",
    "def CAM_multiclass(model,img_set,which_label=None):\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    final_conv = model.layers[-3]\n",
    "    get_output = K.function([model.layers[0].input],[final_conv.output,model.layers[-1].output])\n",
    "\n",
    "    cam_output = np.zeros(shape = [img_set.shape[0],img_set.shape[1],img_set.shape[2],3])\n",
    "\n",
    "    for img_index in range(img_set.shape[0]):\n",
    "        input_img = img_set[img_index:img_index+1,...]\n",
    "        #input_img_rgb = np.concatenate([input_img, input_img, input_img], axis = 3)\n",
    "        [conv_output,predictions] = get_output([input_img])\n",
    "        conv_output = conv_output[0,...]\n",
    "        pred_label = np.argmax(predictions)\n",
    "\n",
    "        cam = np.zeros(shape = conv_output.shape[:-1])\n",
    "        if which_label==None:\n",
    "            for i, w in enumerate(class_weights[:, pred_label]): \n",
    "                cam += w * conv_output[...,i]\n",
    "        if not (which_label==None):\n",
    "            for i, w in enumerate(class_weights[:,  which_label[img_index] ]): \n",
    "                cam += w * conv_output[...,i]\n",
    "        cam /= np.max(cam)\n",
    "\n",
    "        cam_resize = cv2.resize(cam[:,:], (img_set.shape[2],img_set.shape[1]))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*cam_resize), cv2.COLORMAP_JET)\n",
    "        heatmap = heatmap[...,(2,1,0)]\n",
    "        heatmap[np.where(cam_resize < 0.1)] = 0\n",
    "        cam_output[img_index,:,:,:] = heatmap*0.3 + input_img[0,:,:,:]*255\n",
    "        #cam_output[img_index,:,:,:] = heatmap*0.5 + input_img_rgb[0,:,:,:]\n",
    "            \n",
    "    return cam_output\n",
    "\n",
    "pred_te = model.predict(input_te, batch_size=4)\n",
    "pred_label_te = np.argmax(pred_te,axis=1).astype(\"str\")\n",
    "pred_label_te = np.where(pred_label_te==\"1\", \"normal\", pred_label_te)\n",
    "pred_label_te = np.where(pred_label_te==\"0\", \"abnormal\", pred_label_te)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "auc_te = roc_auc_score(target_te[:,0],pred_te[:,0])\n",
    "\n",
    "acc_te = accuracy_score(target_label_te, pred_label_te)\n",
    "cf_mtx = confusion_matrix(target_label_te,pred_label_te)\n",
    "pr_re_f1_report = classification_report(y_true = target_label_te, y_pred = pred_label_te)\n",
    "\n",
    "\n",
    "result_report = pd.DataFrame(data = {\"ID\":[s.split(\"/\")[-1] for s in path_te]\n",
    "                                     ,\"GT_Label\" : target_label_te \n",
    "                                     ,\"pred_Label\" : pred_label_te\n",
    "                                 ,\"GT\" : [str(s) for s in target_te ]\n",
    "                                 ,\"pred\" : [str(s) for s in np.round(pred_te,3) ]\n",
    "                                 ,\"Correct?\" : np.array(target_label_te)==np.array(pred_label_te) })\n",
    "result_report = result_report[['ID',\"GT_Label\",\"pred_Label\",'GT','pred','Correct?']]\n",
    "\n",
    "\n",
    "result_report.to_csv(\"pred_rslt_TE\"+run_name+\".csv\",index=False)\n",
    "\n",
    "pd.set_option('display.width', 999999)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 99999)\n",
    "\n",
    "with open(\"Report-\"+run_name+\".txt\",'w') as text_file:\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Overall accuracy on test set : \",acc_te,file=text_file)\n",
    "    print(\"AUC on test set : \",auc_te,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Confusion Matrix (row=actual, col=predicted)\",file=text_file)\n",
    "    print(\"abnormal / normal\",file=text_file)\n",
    "#     print(class_name_list,file=text_file)\n",
    "    print(cf_mtx,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Classification Report :\",file=text_file)\n",
    "    print(pr_re_f1_report,file=text_file)\n",
    "    print(\"------------------RESULT REPORT--------------------\",file=text_file)\n",
    "    print(result_report,file=text_file)\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')\n",
    "\n",
    "cam_rslt_te = CAM_multiclass(model,input_te)\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(\"./CAM/\"+run_name,exist_ok=True)\n",
    "for i in range(len(pred_label_te)):\n",
    "    cv2.imwrite(\"./CAM/\"+run_name+\"/target\"+str(target_label_te[i])+\"pred\"+str(pred_label_te[i])+\"-ID_\"+str(path_te[i].split(\"\\\\\")[-1])\n",
    "               ,cam_rslt_te[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_path_1 = all_path_1_3\n",
    "run_name = run_name_origin+\"_3\"\n",
    "\n",
    "\n",
    "\n",
    "# normal =0, abn = 1\n",
    "path_tr_0 = all_path_0[:111]\n",
    "path_tr_1 = all_path_1[:111]\n",
    "\n",
    "path_vl_0 = all_path_0[int(len(all_path_0)*tr_ratio):int(len(all_path_0)*(1-te_ratio))]\n",
    "path_vl_1 = all_path_1[int(len(all_path_0)*tr_ratio):int(len(all_path_1)*(1-te_ratio))]\n",
    "path_vl_1 = path_vl_1[:len(path_vl_0)]\n",
    "\n",
    "path_te_0 = all_path_0[-38:]\n",
    "path_te_1 = all_path_1[-60:]\n",
    "\n",
    "path_tr = np.concatenate([path_tr_0,path_tr_1])\n",
    "path_vl = np.concatenate([path_vl_0,path_vl_1])\n",
    "path_te = np.concatenate([path_te_0,path_te_1])\n",
    "\n",
    "target_label_tr = ['normal']*len(path_tr_0) +['abnormal']*len(path_tr_1)\n",
    "target_label_vl = ['normal']*len(path_vl_0) +['abnormal']*len(path_vl_1)\n",
    "target_label_te = ['normal']*len(path_te_0) +['abnormal']*len(path_te_1)\n",
    "\n",
    "target_tr = np.asarray(pd.get_dummies(target_label_tr))\n",
    "target_vl = np.asarray(pd.get_dummies(target_label_vl))\n",
    "target_te = np.asarray(pd.get_dummies(target_label_te))\n",
    "# abnormal = [1,0]   normal = [0,1]\n",
    "\n",
    "\n",
    "print( np.unique(target_label_tr,return_counts=True) )\n",
    "print( np.unique(target_label_vl,return_counts=True) )\n",
    "print( np.unique(target_label_te,return_counts=True) )\n",
    "print(target_tr[:5])\n",
    "print(target_label_tr[:5])\n",
    "\n",
    "\n",
    "input_tr = load_many_image(path_tr)\n",
    "input_vl = load_many_image(path_vl)\n",
    "input_te = load_many_image(path_te)\n",
    "\n",
    "datagen_tr = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range = [0.9,1.1],\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval = 0)\n",
    "datagen_te = ImageDataGenerator()\n",
    "\n",
    "gen_tr = datagen_tr.flow(x = input_tr,y=target_tr,batch_size=8)\n",
    "gen_vl = datagen_te.flow(x = input_vl,y=target_vl,batch_size=8)\n",
    "gen_te = datagen_te.flow(x = input_te,y=target_te,batch_size=8)\n",
    "\n",
    "step_per_epoch = int( len(input_tr)/8 )\n",
    "\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "predictions = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "callback_tb = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/\"+run_name+\"/\".format(run_name), profile_batch = 100000000)\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath = run_name+\"_best.hdf5\",monitor='val_accuracy',\n",
    "                                                verbose=1, save_best_only=True,mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x = gen_tr, epochs=epoch, \n",
    "          validation_data=gen_vl, \n",
    "          steps_per_epoch = step_per_epoch,\n",
    "                    max_queue_size=15,\n",
    "                    workers=8,\n",
    "          callbacks=[callback_tb,callback_mc])\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(run_name+\"_best.hdf5\")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "\n",
    "def CAM_multiclass(model,img_set,which_label=None):\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    final_conv = model.layers[-3]\n",
    "    get_output = K.function([model.layers[0].input],[final_conv.output,model.layers[-1].output])\n",
    "\n",
    "    cam_output = np.zeros(shape = [img_set.shape[0],img_set.shape[1],img_set.shape[2],3])\n",
    "\n",
    "    for img_index in range(img_set.shape[0]):\n",
    "        input_img = img_set[img_index:img_index+1,...]\n",
    "        #input_img_rgb = np.concatenate([input_img, input_img, input_img], axis = 3)\n",
    "        [conv_output,predictions] = get_output([input_img])\n",
    "        conv_output = conv_output[0,...]\n",
    "        pred_label = np.argmax(predictions)\n",
    "\n",
    "        cam = np.zeros(shape = conv_output.shape[:-1])\n",
    "        if which_label==None:\n",
    "            for i, w in enumerate(class_weights[:, pred_label]): \n",
    "                cam += w * conv_output[...,i]\n",
    "        if not (which_label==None):\n",
    "            for i, w in enumerate(class_weights[:,  which_label[img_index] ]):  \n",
    "                cam += w * conv_output[...,i]\n",
    "        cam /= np.max(cam)\n",
    "\n",
    "        cam_resize = cv2.resize(cam[:,:], (img_set.shape[2],img_set.shape[1]))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*cam_resize), cv2.COLORMAP_JET)\n",
    "        heatmap = heatmap[...,(2,1,0)]\n",
    "        heatmap[np.where(cam_resize < 0.1)] = 0\n",
    "        cam_output[img_index,:,:,:] = heatmap*0.3 + input_img[0,:,:,:]*255\n",
    "        #cam_output[img_index,:,:,:] = heatmap*0.5 + input_img_rgb[0,:,:,:]\n",
    "            \n",
    "    return cam_output\n",
    "\n",
    "pred_te = model.predict(input_te, batch_size=4)\n",
    "pred_label_te = np.argmax(pred_te,axis=1).astype(\"str\")\n",
    "pred_label_te = np.where(pred_label_te==\"1\", \"normal\", pred_label_te)\n",
    "pred_label_te = np.where(pred_label_te==\"0\", \"abnormal\", pred_label_te)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "auc_te = roc_auc_score(target_te[:,0],pred_te[:,0])\n",
    "\n",
    "acc_te = accuracy_score(target_label_te, pred_label_te)\n",
    "cf_mtx = confusion_matrix(target_label_te,pred_label_te)\n",
    "pr_re_f1_report = classification_report(y_true = target_label_te, y_pred = pred_label_te)\n",
    "\n",
    "\n",
    "result_report = pd.DataFrame(data = {\"ID\":[s.split(\"/\")[-1] for s in path_te]\n",
    "                                     ,\"GT_Label\" : target_label_te \n",
    "                                     ,\"pred_Label\" : pred_label_te\n",
    "                                 ,\"GT\" : [str(s) for s in target_te ]\n",
    "                                 ,\"pred\" : [str(s) for s in np.round(pred_te,3) ]\n",
    "                                 ,\"Correct?\" : np.array(target_label_te)==np.array(pred_label_te) })\n",
    "result_report = result_report[['ID',\"GT_Label\",\"pred_Label\",'GT','pred','Correct?']]\n",
    "\n",
    "\n",
    "result_report.to_csv(\"pred_rslt_TE\"+run_name+\".csv\",index=False)\n",
    "\n",
    "pd.set_option('display.width', 999999)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 99999)\n",
    "\n",
    "with open(\"Report-\"+run_name+\".txt\",'w') as text_file:\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Overall accuracy on test set : \",acc_te,file=text_file)\n",
    "    print(\"AUC on test set : \",auc_te,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Confusion Matrix (row=actual, col=predicted)\",file=text_file)\n",
    "    print(\"abnormal / normal\",file=text_file)\n",
    "#     print(class_name_list,file=text_file)\n",
    "    print(cf_mtx,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Classification Report :\",file=text_file)\n",
    "    print(pr_re_f1_report,file=text_file)\n",
    "    print(\"------------------RESULT REPORT--------------------\",file=text_file)\n",
    "    print(result_report,file=text_file)\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')\n",
    "\n",
    "cam_rslt_te = CAM_multiclass(model,input_te)\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(\"./CAM/\"+run_name,exist_ok=True)\n",
    "for i in range(len(pred_label_te)):\n",
    "    cv2.imwrite(\"./CAM/\"+run_name+\"/target\"+str(target_label_te[i])+\"pred\"+str(pred_label_te[i])+\"-ID_\"+str(path_te[i].split(\"\\\\\")[-1])\n",
    "               ,cam_rslt_te[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_path_1 = all_path_1_4\n",
    "\n",
    "run_name = run_name_origin+\"_4\"\n",
    "\n",
    "\n",
    "# normal =0, abn = 1\n",
    "path_tr_0 = all_path_0[:111]\n",
    "path_tr_1 = all_path_1[:111]\n",
    "\n",
    "path_vl_0 = all_path_0[int(len(all_path_0)*tr_ratio):int(len(all_path_0)*(1-te_ratio))]\n",
    "path_vl_1 = all_path_1[int(len(all_path_0)*tr_ratio):int(len(all_path_1)*(1-te_ratio))]\n",
    "path_vl_1 = path_vl_1[:len(path_vl_0)]\n",
    "\n",
    "path_te_0 = all_path_0[-38:]\n",
    "path_te_1 = all_path_1[-60:]\n",
    "\n",
    "path_tr = np.concatenate([path_tr_0,path_tr_1])\n",
    "path_vl = np.concatenate([path_vl_0,path_vl_1])\n",
    "path_te = np.concatenate([path_te_0,path_te_1])\n",
    "\n",
    "target_label_tr = ['normal']*len(path_tr_0) +['abnormal']*len(path_tr_1)\n",
    "target_label_vl = ['normal']*len(path_vl_0) +['abnormal']*len(path_vl_1)\n",
    "target_label_te = ['normal']*len(path_te_0) +['abnormal']*len(path_te_1)\n",
    "\n",
    "target_tr = np.asarray(pd.get_dummies(target_label_tr))\n",
    "target_vl = np.asarray(pd.get_dummies(target_label_vl))\n",
    "target_te = np.asarray(pd.get_dummies(target_label_te))\n",
    "# abnormal = [1,0]   normal = [0,1]\n",
    "\n",
    "\n",
    "print( np.unique(target_label_tr,return_counts=True) )\n",
    "print( np.unique(target_label_vl,return_counts=True) )\n",
    "print( np.unique(target_label_te,return_counts=True) )\n",
    "print(target_tr[:5])\n",
    "print(target_label_tr[:5])\n",
    "\n",
    "\n",
    "input_tr = load_many_image(path_tr)\n",
    "input_vl = load_many_image(path_vl)\n",
    "input_te = load_many_image(path_te)\n",
    "\n",
    "datagen_tr = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range = [0.9,1.1],\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval = 0)\n",
    "datagen_te = ImageDataGenerator()\n",
    "\n",
    "gen_tr = datagen_tr.flow(x = input_tr,y=target_tr,batch_size=8)\n",
    "gen_vl = datagen_te.flow(x = input_vl,y=target_vl,batch_size=8)\n",
    "gen_te = datagen_te.flow(x = input_te,y=target_te,batch_size=8)\n",
    "\n",
    "step_per_epoch = int( len(input_tr)/8 )\n",
    "\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "predictions = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "callback_tb = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/\"+run_name+\"/\".format(run_name), profile_batch = 100000000)\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath = run_name+\"_best.hdf5\",monitor='val_accuracy',\n",
    "                                                verbose=1, save_best_only=True,mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x = gen_tr, epochs=epoch, \n",
    "          validation_data=gen_vl, \n",
    "          steps_per_epoch = step_per_epoch,\n",
    "                    max_queue_size=15,\n",
    "                    workers=8,\n",
    "          callbacks=[callback_tb,callback_mc])\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(run_name+\"_best.hdf5\")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "\n",
    "def CAM_multiclass(model,img_set,which_label=None):\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    final_conv = model.layers[-3]\n",
    "    get_output = K.function([model.layers[0].input],[final_conv.output,model.layers[-1].output])\n",
    "\n",
    "    cam_output = np.zeros(shape = [img_set.shape[0],img_set.shape[1],img_set.shape[2],3])\n",
    "\n",
    "    for img_index in range(img_set.shape[0]):\n",
    "        input_img = img_set[img_index:img_index+1,...]\n",
    "        #input_img_rgb = np.concatenate([input_img, input_img, input_img], axis = 3)\n",
    "        [conv_output,predictions] = get_output([input_img])\n",
    "        conv_output = conv_output[0,...]\n",
    "        pred_label = np.argmax(predictions)\n",
    "\n",
    "        cam = np.zeros(shape = conv_output.shape[:-1])\n",
    "        if which_label==None:\n",
    "            for i, w in enumerate(class_weights[:, pred_label]): \n",
    "                cam += w * conv_output[...,i]\n",
    "        if not (which_label==None):\n",
    "            for i, w in enumerate(class_weights[:,  which_label[img_index] ]):  \n",
    "                cam += w * conv_output[...,i]\n",
    "        cam /= np.max(cam)\n",
    "\n",
    "        cam_resize = cv2.resize(cam[:,:], (img_set.shape[2],img_set.shape[1]))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*cam_resize), cv2.COLORMAP_JET)\n",
    "        heatmap = heatmap[...,(2,1,0)]\n",
    "        heatmap[np.where(cam_resize < 0.1)] = 0\n",
    "        cam_output[img_index,:,:,:] = heatmap*0.3 + input_img[0,:,:,:]*255\n",
    "        #cam_output[img_index,:,:,:] = heatmap*0.5 + input_img_rgb[0,:,:,:]\n",
    "            \n",
    "    return cam_output\n",
    "\n",
    "pred_te = model.predict(input_te, batch_size=4)\n",
    "pred_label_te = np.argmax(pred_te,axis=1).astype(\"str\")\n",
    "pred_label_te = np.where(pred_label_te==\"1\", \"normal\", pred_label_te)\n",
    "pred_label_te = np.where(pred_label_te==\"0\", \"abnormal\", pred_label_te)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "auc_te = roc_auc_score(target_te[:,0],pred_te[:,0])\n",
    "\n",
    "acc_te = accuracy_score(target_label_te, pred_label_te)\n",
    "cf_mtx = confusion_matrix(target_label_te,pred_label_te)\n",
    "pr_re_f1_report = classification_report(y_true = target_label_te, y_pred = pred_label_te)\n",
    "\n",
    "\n",
    "result_report = pd.DataFrame(data = {\"ID\":[s.split(\"/\")[-1] for s in path_te]\n",
    "                                     ,\"GT_Label\" : target_label_te \n",
    "                                     ,\"pred_Label\" : pred_label_te\n",
    "                                 ,\"GT\" : [str(s) for s in target_te ]\n",
    "                                 ,\"pred\" : [str(s) for s in np.round(pred_te,3) ]\n",
    "                                 ,\"Correct?\" : np.array(target_label_te)==np.array(pred_label_te) })\n",
    "result_report = result_report[['ID',\"GT_Label\",\"pred_Label\",'GT','pred','Correct?']]\n",
    "\n",
    "\n",
    "result_report.to_csv(\"pred_rslt_TE\"+run_name+\".csv\",index=False)\n",
    "\n",
    "pd.set_option('display.width', 999999)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 99999)\n",
    "\n",
    "with open(\"Report-\"+run_name+\".txt\",'w') as text_file:\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Overall accuracy on test set : \",acc_te,file=text_file)\n",
    "    print(\"AUC on test set : \",auc_te,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Confusion Matrix (row=actual, col=predicted)\",file=text_file)\n",
    "    print(\"abnormal / normal\",file=text_file)\n",
    "#     print(class_name_list,file=text_file)\n",
    "    print(cf_mtx,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Classification Report :\",file=text_file)\n",
    "    print(pr_re_f1_report,file=text_file)\n",
    "    print(\"------------------RESULT REPORT--------------------\",file=text_file)\n",
    "    print(result_report,file=text_file)\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')\n",
    "\n",
    "cam_rslt_te = CAM_multiclass(model,input_te)\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(\"./CAM/\"+run_name,exist_ok=True)\n",
    "for i in range(len(pred_label_te)):\n",
    "    cv2.imwrite(\"./CAM/\"+run_name+\"/target\"+str(target_label_te[i])+\"pred\"+str(pred_label_te[i])+\"-ID_\"+str(path_te[i].split(\"\\\\\")[-1])\n",
    "               ,cam_rslt_te[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_path_1 = all_path_1_5\n",
    "run_name = run_name_origin+\"_5\"\n",
    "\n",
    "\n",
    "\n",
    "# normal =0, abn = 1\n",
    "path_tr_0 = all_path_0[:111]\n",
    "path_tr_1 = all_path_1[:111]\n",
    "\n",
    "path_vl_0 = all_path_0[int(len(all_path_0)*tr_ratio):int(len(all_path_0)*(1-te_ratio))]\n",
    "path_vl_1 = all_path_1[int(len(all_path_0)*tr_ratio):int(len(all_path_1)*(1-te_ratio))]\n",
    "path_vl_1 = path_vl_1[:len(path_vl_0)]\n",
    "\n",
    "path_te_0 = all_path_0[-38:]\n",
    "path_te_1 = all_path_1[-60:]\n",
    "\n",
    "path_tr = np.concatenate([path_tr_0,path_tr_1])\n",
    "path_vl = np.concatenate([path_vl_0,path_vl_1])\n",
    "path_te = np.concatenate([path_te_0,path_te_1])\n",
    "\n",
    "target_label_tr = ['normal']*len(path_tr_0) +['abnormal']*len(path_tr_1)\n",
    "target_label_vl = ['normal']*len(path_vl_0) +['abnormal']*len(path_vl_1)\n",
    "target_label_te = ['normal']*len(path_te_0) +['abnormal']*len(path_te_1)\n",
    "\n",
    "target_tr = np.asarray(pd.get_dummies(target_label_tr))\n",
    "target_vl = np.asarray(pd.get_dummies(target_label_vl))\n",
    "target_te = np.asarray(pd.get_dummies(target_label_te))\n",
    "# abnormal = [1,0]   normal = [0,1]\n",
    "\n",
    "\n",
    "print( np.unique(target_label_tr,return_counts=True) )\n",
    "print( np.unique(target_label_vl,return_counts=True) )\n",
    "print( np.unique(target_label_te,return_counts=True) )\n",
    "print(target_tr[:5])\n",
    "print(target_label_tr[:5])\n",
    "\n",
    "\n",
    "input_tr = load_many_image(path_tr)\n",
    "input_vl = load_many_image(path_vl)\n",
    "input_te = load_many_image(path_te)\n",
    "\n",
    "datagen_tr = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range = [0.9,1.1],\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval = 0)\n",
    "datagen_te = ImageDataGenerator()\n",
    "\n",
    "gen_tr = datagen_tr.flow(x = input_tr,y=target_tr,batch_size=8)\n",
    "gen_vl = datagen_te.flow(x = input_vl,y=target_vl,batch_size=8)\n",
    "gen_te = datagen_te.flow(x = input_te,y=target_te,batch_size=8)\n",
    "\n",
    "step_per_epoch = int( len(input_tr)/8 )\n",
    "\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "predictions = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "callback_tb = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/\"+run_name+\"/\".format(run_name), profile_batch = 100000000)\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath = run_name+\"_best.hdf5\",monitor='val_accuracy',\n",
    "                                                verbose=1, save_best_only=True,mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x = gen_tr, epochs=epoch, \n",
    "          validation_data=gen_vl, \n",
    "          steps_per_epoch = step_per_epoch,\n",
    "                    max_queue_size=15,\n",
    "                    workers=8,\n",
    "          callbacks=[callback_tb,callback_mc])\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(run_name+\"_best.hdf5\")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "\n",
    "def CAM_multiclass(model,img_set,which_label=None):\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    final_conv = model.layers[-3]\n",
    "    get_output = K.function([model.layers[0].input],[final_conv.output,model.layers[-1].output])\n",
    "\n",
    "    cam_output = np.zeros(shape = [img_set.shape[0],img_set.shape[1],img_set.shape[2],3])\n",
    "\n",
    "    for img_index in range(img_set.shape[0]):\n",
    "        input_img = img_set[img_index:img_index+1,...]\n",
    "        #input_img_rgb = np.concatenate([input_img, input_img, input_img], axis = 3)\n",
    "        [conv_output,predictions] = get_output([input_img])\n",
    "        conv_output = conv_output[0,...]\n",
    "        pred_label = np.argmax(predictions)\n",
    "\n",
    "        cam = np.zeros(shape = conv_output.shape[:-1])\n",
    "        if which_label==None:\n",
    "            for i, w in enumerate(class_weights[:, pred_label]): \n",
    "                cam += w * conv_output[...,i]\n",
    "        if not (which_label==None):\n",
    "            for i, w in enumerate(class_weights[:,  which_label[img_index] ]): \n",
    "                cam += w * conv_output[...,i]\n",
    "        cam /= np.max(cam)\n",
    "\n",
    "        cam_resize = cv2.resize(cam[:,:], (img_set.shape[2],img_set.shape[1]))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*cam_resize), cv2.COLORMAP_JET)\n",
    "        heatmap = heatmap[...,(2,1,0)]\n",
    "        heatmap[np.where(cam_resize < 0.1)] = 0\n",
    "        cam_output[img_index,:,:,:] = heatmap*0.3 + input_img[0,:,:,:]*255\n",
    "        #cam_output[img_index,:,:,:] = heatmap*0.5 + input_img_rgb[0,:,:,:]\n",
    "            \n",
    "    return cam_output\n",
    "\n",
    "pred_te = model.predict(input_te, batch_size=4)\n",
    "pred_label_te = np.argmax(pred_te,axis=1).astype(\"str\")\n",
    "pred_label_te = np.where(pred_label_te==\"1\", \"normal\", pred_label_te)\n",
    "pred_label_te = np.where(pred_label_te==\"0\", \"abnormal\", pred_label_te)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "auc_te = roc_auc_score(target_te[:,0],pred_te[:,0])\n",
    "\n",
    "acc_te = accuracy_score(target_label_te, pred_label_te)\n",
    "cf_mtx = confusion_matrix(target_label_te,pred_label_te)\n",
    "pr_re_f1_report = classification_report(y_true = target_label_te, y_pred = pred_label_te)\n",
    "\n",
    "\n",
    "result_report = pd.DataFrame(data = {\"ID\":[s.split(\"/\")[-1] for s in path_te]\n",
    "                                     ,\"GT_Label\" : target_label_te \n",
    "                                     ,\"pred_Label\" : pred_label_te\n",
    "                                 ,\"GT\" : [str(s) for s in target_te ]\n",
    "                                 ,\"pred\" : [str(s) for s in np.round(pred_te,3) ]\n",
    "                                 ,\"Correct?\" : np.array(target_label_te)==np.array(pred_label_te) })\n",
    "result_report = result_report[['ID',\"GT_Label\",\"pred_Label\",'GT','pred','Correct?']]\n",
    "\n",
    "\n",
    "result_report.to_csv(\"pred_rslt_TE\"+run_name+\".csv\",index=False)\n",
    "\n",
    "pd.set_option('display.width', 999999)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 99999)\n",
    "\n",
    "with open(\"Report-\"+run_name+\".txt\",'w') as text_file:\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Overall accuracy on test set : \",acc_te,file=text_file)\n",
    "    print(\"AUC on test set : \",auc_te,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Confusion Matrix (row=actual, col=predicted)\",file=text_file)\n",
    "    print(\"abnormal / normal\",file=text_file)\n",
    "#     print(class_name_list,file=text_file)\n",
    "    print(cf_mtx,file=text_file)\n",
    "    print(\"\",file=text_file)\n",
    "    print(\"Classification Report :\",file=text_file)\n",
    "    print(pr_re_f1_report,file=text_file)\n",
    "    print(\"------------------RESULT REPORT--------------------\",file=text_file)\n",
    "    print(result_report,file=text_file)\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')\n",
    "\n",
    "cam_rslt_te = CAM_multiclass(model,input_te)\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(\"./CAM/\"+run_name,exist_ok=True)\n",
    "for i in range(len(pred_label_te)):\n",
    "    cv2.imwrite(\"./CAM/\"+run_name+\"/target\"+str(target_label_te[i])+\"pred\"+str(pred_label_te[i])+\"-ID_\"+str(path_te[i].split(\"\\\\\")[-1])\n",
    "               ,cam_rslt_te[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
